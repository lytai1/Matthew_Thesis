import dill
import os
import argparse

from dipy.data import get_sphere
from dipy.viz import actor, window, ui
import numpy as np

import psutil

print(psutil.virtual_memory())

class Results():

    def __init__(self, model, patient_num):
        
        self.patient_num = patient_num
        
        self.model = model
        print("Generating volume image")
        self.volume_image = self.aquire_odi(model.fitted_parameters)
        print("Generating fods")
        self.fod = self.calculate_fod(model)
        
        
    """
        get the base slide of the brain (middle ODI layer). Normalize it by a 4x4 array.
    """
    def aquire_odi(self, fitted_parameters):

        affine = np.eye(4)

        volume_res = fitted_parameters['SD1WatsonDistributed_1_SD1Watson_1_odi']
        volume_im = actor.slicer(volume_res, interpolation='nearest', affine=affine, opacity=0.7)
        
        #z = int(np.round(volume_im.shape[2]/2))- 1
        #volume_im.display_extent(0, volume_im.shape[0] - 1,
        #                         0, volume_im.shape[1] - 1,
        #                         z, z)
        
        return volume_im
    
    
    """
        calcuate the fod of the middle slide of the brain. convert values to cylinders.
    """    
    def calculate_fod(self, model):

        sphere = get_sphere(name = 'symmetric724').subdivide()
        print("calculating fod")
        fods = model.fod(sphere.vertices, visual_odi_lower_bound = 0.18)
        print("finsih fod calculation. Start odf splicer")
        fod_spheres = actor.odf_slicer(fods, sphere=sphere, scale=1.0, norm=False, opacity=1.0)
        print("finish splicer")

        return fod_spheres
    
    """
        display both the odi layer and fod layer in a separate window.
        Also save the image in 2d in .png format.
    """
    def display(self):
        ren = window.Renderer()
        
        ren.add(self.volume_image)
        ren.add(self.fod)
        
        show_m = window.ShowManager(ren, size=(1200, 900))
        show_m.initialize()
        
        interactive = True

        ren.zoom(1.5)
        ren.reset_clipping_range()

        if interactive:

            show_m.render()
            show_m.start()

        path = self.patient_num + ".png"

        window.record(ren, out_path=path, size=(1200, 900),
                          reset_camera=False)
        del show_m



"""
Description:

It takes a pickle file generated by NODDI analysis and generate a 3D image of a slice of the brain with ODI vectors on it.

Help:
    --path     The path to the location of the pickle file 

example command:

python viz_try.py --path pickel_files/003_S_6268_bl.pkl

"""

  
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Takes a pickle file generated by the training of a model on the specific mri")
    parser.add_argument('--path', metavar='-p', type=str, help="The path to the location of the pickle file")
    
    args = parser.parse_args()

    print("Loading model") 
    ## load the model 
    with open(args.path, "rb") as f:
        model = dill.load(f)


    path, name = os.path.split(args.path)
    patient_num, ext = os.path.splitext(name)
 
    ## generate the fod and resulting volume image then display them
    print("Generating visualization parameters")
    result = Results(model, patient_num)
    result.display()
    